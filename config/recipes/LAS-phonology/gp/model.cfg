[io]
#a space seperated list of input names
inputs = features
#a space seperated list of output names
outputs = text

[encoder]
encoder = stack_encoder
stack = phonologyhs listener

[phonologyhs]
#type of encoder
encoder = hotstart_encoder
#the section of the wrapped encoder
wrapped = phonology
#directory forthe starting values of the variables
modeldir = /esat/spchtemp/scratch/matthias/TIMIT/aug28_3/logdir/model.ckpt-13860
#whether the loaded variables are trainable or not
trainable = False

[phonology]
#type of encoder
encoder = bldnn
#number of neurons in the hidden ff layers
blstm_units = 256
#number of hidden ff layers
blstm_layers = 0
#dropout rate in ff layers
blstm_dropout = 0.8
#number of neurons in the hidden ff layers
ff_units = 2048
#number of hidden ff layers
ff_layers = 6
#dropout rate in ff layers
ff_dropout = 0.5
#number of left and right context windows to take into account
context = 3
#whether layer normalization should be applied in the feedforward layers
layer_norm = True

[listener]
#type of encoder
encoder = listener
#the standard deviation of the Gaussian input noise added during training
input_noise = 0.6
#number of pyramidal layers a non-pyramidal layer is added at the end
num_layers = 2
#number of units in each layer
num_units = 128
#number of timesteps to concatenate in each pyramidal layer
pyramid_steps = 2
#dropout rate
dropout = 1
#whether layer normalization should be used
layer_norm = True

[decoder]
#type of decoder
decoder = speller
#number of layers
num_layers = 2
#number of units
num_units = 128
#the probability that the network will sample from the output during training
sample_prob = 0.1
#whether layer normalization should be used
layer_norm = True
#the output dimensions AR(47) FR(43) GE(45) PO(61) SP(46) SW(35) TU(50)
output_dims = 45
