# Normal execution
Universe         = vanilla
# just 1 GPU for the parameter server
request_GPUs      = 1
# only need a little RAM because the GPU will be used
RequestMemory    = 100M
#specify that the cuda capability should be at least 3.0 and set the memory
#requirement
Requirements = (CUDACapability >= 3.0)\
  &&(CUDAGlobalMemoryMb >= 4000)\

#Specify nice user behavior
NiceUser = true
#Send an email in case of an error
Notification = Error
#stream the output so it can be folowed
stream_output = True

# Should run from the project directory
initialdir = .

#Run he build cluster script for the worker
Arguments = "python build_cluster.py --job_name=worker --expdir=$(expdir)"
#Run the condor job wapper to adjust the environment
executable = distributed/condor/create_environment.sh

#Output of condors handling of the jobs, will be in 'initialdir'
Log          = $(expdir)/outputs/worker-$(Process).log
#Standard output of the 'executable', in 'initialdir'
Output       = $(expdir)/outputs/worker-$(Process).out
#Standard error of the 'executable', in 'initialdir'
Error        = $(expdir)/outputs/worker-$(Process).err

# Queue however many parameter servers were requested
Queue $(numjobs)
